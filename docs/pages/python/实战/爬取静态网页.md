## 什么是静态网页
在网页上, 右键 -> 查看网页源代码 -> 如果能找到你想要爬取的数据, 就证明是一个被渲染好的静态页面 (如果没有数据, 则证明是js动态渲染的, 这个文章暂时不说爬取动态数据的网页)
## 准备工作
0. 电脑安装python3程序软件(内置pip3功能) 

   [下载地址](https://www.python.org/downloads/)  (注意python3的命令都得带python3 / pip3)
> 本案例 python3.7.0 pip版本10.0.1  (命令python3 --version, pip3 --version查看)
1. 准备vscode编辑器
2. 新建index.py的python文件
3. 在当前工程中, 下载需要的插件包(pip install lxml requests pymysql)
    * lxml 用于分析网页结构, 分解出网页标签
    * requests 用于获取目标url网页上的源代码
    * pymysql 用于连接数据库和操作数据库
``` python
#coding:utf-8
# 第一行让当前页的中文都以utf-8编码运行
# 导入 lxml 库(负责分析标签结构的), requests库(负责把目标url的网页源代码都请求下来的)  pymysql库(负责链接和操作数据库的)
from lxml import etree
import requests
import pymysql

# 创建数据库链接
db = pymysql.connect(host="localhost", user="root", password="", port=3306, database="xiaou", charset='utf8')
# 创建游标
cursor = db.cursor()

# 在这里填入你要爬取的目标网址
html = requests.get("http://lidongxuwork.gitee.io/lidongxu123/")
# 输入爬取下来的数据编码(标签+内容)
html.encoding = 'utf-8' 
# 获取到根标签
xh = etree.HTML(html.text)
# 从根标签寻找div的class叫..下面的li标签
arr = xh.xpath("//div[@class='category_con']/ul/li")
# 遍历每个li标签
for index, el in enumerate(arr):
    # 获取当前li标签下的a标签里的文本
    contentArr = el.xpath("./a/text()")
    # 标签每组li下拿到的文字
    for index2, theStr in enumerate(contentArr):
        # 编写sql语句
        sql = "INSERT INTO ttt(id, category_name, row) VALUES(null, '"+ theStr + "', '" + str(index2) + "')"
        # 执行SQL语句
        cursor.execute(sql)
        # 必须提交, 才会真正执行到MySQL数据库里(查询则不用commit)
        db.commit()
```
最后效果:
注意, id是自增, 我们不同很正常的
![](/python/Snip20200710_7.png)

